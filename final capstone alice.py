# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X-a2Zen0-c3DfzAk-9L5to8jepqjlxRT
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split

from scipy import stats
from scipy.stats import pearsonr
from scipy.stats import mannwhitneyu
from scipy.stats import t

from sklearn.decomposition import PCA

from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import roc_curve, auc, roc_auc_score

from scipy.special import expit
import random
random.seed(a= "N13232728")

data = pd.read_csv("spotify52kData.csv")
#index
data.reset_index(drop=True)

"""Q1: Consider the 10 song features duration, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence and tempo. Is any of these features reasonably distributed normally? If so, which one? [Suggestion: Include a 2x5 figure with histograms for each feature]"""

features = ['duration', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']
#distributed normally
fig, axes = plt.subplots(2, 5, figsize=(20, 8))
fig.suptitle('10 Song Features', fontsize=16)
for i, feature in enumerate(features):
    row = i // 5
    col = i % 5
    axes[row, col].hist(data[feature], bins=20, color='skyblue', edgecolor='black')
    axes[row, col].set_title(feature)
    axes[row, col].set_xlabel('Value')
    axes[row, col].set_ylabel('Frequency')
plt.tight_layout()
plt.show()

"""Q2: Is there a relationship between song length and popularity of a song? If so, if the relationship positive or negative? [Suggestion: Include a scatterplot]"""

plt.figure(figsize=(8, 6))
plt.scatter(data['duration'], data['popularity'], alpha=0.5, color='steelblue')
plt.title('Song Duration vs. Popularity')
plt.xlabel('Duration (ms)')
plt.ylabel('Popularity')

# Calculate correlation coefficient
correlation_coefficient, _ = pearsonr(data['duration'], data['popularity'])

# Plot correlation line
z = np.polyfit(data['duration'], data['popularity'], 1)
p = np.poly1d(z)
plt.plot(data['duration'], p(data['duration']), color='lightgreen', linestyle='-', label=f'Correlation Coefficient: {correlation_coefficient:.2f}')

plt.legend()
plt.grid(True)
plt.show()

"""Q3: Are explicitly rated songs more popular than songs that are not explicit? [Suggestion: Do a suitable significance test, be it parametric, non-parametric or permutation]"""

explicit_popularity = data[data['explicit'] == True]['popularity']
non_explicit_popularity = data[data['explicit'] == False]['popularity']

stat, pvalue1 = mannwhitneyu(explicit_popularity, non_explicit_popularity)

alpha = 0.05
print(pvalue1)

if pvalue1 < alpha:
    print("The difference in popularity between explicit and non-explicit songs is statistically significant.")
else:
    print("There is no statistically significant difference in popularity between explicit and non-explicit songs.")

plt.hist(explicit_popularity,bins=7)
plt.title("Explicit")
plt.show()

plt.hist(non_explicit_popularity,bins=7)
plt.title("Non_explicit")
plt.show()

plt.figure(figsize=(8, 6))
plt.boxplot([explicit_popularity, non_explicit_popularity], labels=['Explicit', 'Non-Explicit'])
plt.title('Mann-Whitney U test'.format(stat,pvalue1))
plt.ylabel('Popularity')
plt.show()

"""Q4: Are songs in major key more popular than songs in minor key? [Suggestion: Do a suitable significance test, be it parametric, non-parametric or permutation]"""

major_popularity = data[data['mode'] == 1]['popularity']
minor_popularity = data[data['mode'] == 0]['popularity']

stat2, pvalue2 = mannwhitneyu(major_popularity, minor_popularity)

print(f"P-value: {pvalue2:.10f}")

if pvalue2 < alpha:
    print("The difference in popularity between songs in major and minor keys is statistically significant.")
else:
    print("There is no statistically significant difference in popularity between songs in major and minor keys.")

plt.figure(figsize=(8, 6))
plt.boxplot([major_popularity, minor_popularity], labels=['Major', 'Minor'])
plt.title('Mann-Whitney U test'.format(stat2,pvalue2))
plt.ylabel('Popularity')
plt.show()

"""Q5: Energy is believed to largely reflect the “loudness” of a song. Can you substantiate (or refute) that this is the case? [Suggestion: Include a scatterplot]"""

energy = data['energy']
loudness = data['loudness']

plt.figure(figsize=(10, 6))
plt.scatter(energy, loudness, alpha=0.5, color='steelblue')
plt.title('Energy vs. Loudness')
plt.xlabel('Energy')
plt.ylabel('Loudness')
plt.grid(True)

plt.show()
correlation = energy.corr(loudness)
print("correlation between energy and loudness: ", correlation)

"""Q6: Which of the 10 song features in question 1 predicts popularity best? How good is this model?"""

allc = {}
for feature in features:
    sinc = data['popularity'].corr(data[feature])
    allc[feature] = sinc

for feature, correlation in allc.items():
    print(f"correlation coefficient between popularity and {feature}: {correlation}")

best_predictor = max(allc, key=lambda k: abs(allc[k]))
best_correlation = allc[best_predictor]
print("The feature that best predicts popularity is: ", best_predictor)
print("Correlation coefficient: ",best_correlation)

X = data[[best_predictor]].values.reshape(-1, 1)
y = data['popularity'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

predicted_popularity = linear_model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, predicted_popularity))

r_squared = r2_score(y_test, predicted_popularity)

print("RMSE:", rmse)
print("R-squared:", r_squared)

"""Q7: Building a model that uses all of the song features in question 1, how well can you predict popularity?
How much (if at all) is this model improved compared to the model in question 7).
How do you account for this?
"""

X = data[features]
y = data['popularity']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build and train the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluate the model's performance on the testing data
y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("Root Mean Squared Error:", rmse)
print("R-squared:", r2)

#lasso

"""Q8: When considering the 10 song features above, how many meaningful principal components
can you extract? What proportion of the variance do these principal components account for?
"""

zscoredData = stats.zscore(data[features])
pca = PCA().fit(zscoredData)
eigVals = pca.explained_variance_
loadings = pca.components_
rotatedData = pca.fit_transform(zscoredData)
varExplained= eigVals/sum(eigVals)*100
for i in range(len(varExplained)):
    print(varExplained[i].round(3))

df = pd.DataFrame(features)
numdf = len(df)
x = np.linspace(1,numdf,numdf)
plt.bar(x, eigVals, color='gray')
plt.plot([0,numdf],[1,1],color='orange') # Orange Kaiser criterion line for the fox
plt.xlabel('Principal component')
plt.ylabel('Eigenvalue')
plt.show()

kaiserThreshold = 1
print('Number of factors selected by Kaiser criterion:', np.count_nonzero(eigVals > kaiserThreshold))

for whichPrincipalComponent in range(0, 3):
    plt.bar(features, loadings[whichPrincipalComponent, :]*-1)
    plt.ylabel('Loading')
    plt.title('Principal Component {}'.format(whichPrincipalComponent+1))
    plt.xticks(rotation=45)
    plt.show()

principal_components = loadings[:3]

# Display the principal components
for i, component in enumerate(principal_components):
    print(f"Principal Component {i+1}:")
    print(component)
    print()

"""Q9: Can you predict whether a song is in major or minor key from valence? If so, how good is this
prediction? If not, is there a better predictor? [Suggestion: It might be nice to show the logistic
regression once you are done building the model]
"""

X = data[['valence']]
y = data['mode']  # Target variable (major or minor)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

x_values = np.linspace(0, 1, 100).reshape(-1, 1)
y_values = model.predict_proba(x_values)[:, 1]  # Probability of mode = 1 (major)

plt.scatter(X, y, color='black', alpha=0.5)
plt.plot(x_values, y_values, color='red', linewidth=3)
plt.xlabel('Valence')
plt.ylabel('Mode (0=minor, 1=major)')
plt.title('Logistic Regression for Predicting Major/Minor Mode')
plt.axhline(y=0.5, color='gray', linestyle='--')
plt.show()

auroc_scores = {}

# Iterate over each feature
for feature in features:
    # Define X (feature) and y (target variable)
    X = data[[feature]]
    y = data['mode']  # Target variable (major or minor)

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train logistic regression model
    model = LogisticRegression()
    model.fit(X_train, y_train)

    # Predict probabilities for the test set
    y_prob = model.predict_proba(X_test)[:, 1]

    # Calculate AUROC
    auroc = roc_auc_score(y_test, y_prob)

    # Store AUROC score in dictionary
    auroc_scores[feature] = auroc

# Print AUROC scores for each feature
for feature, score in auroc_scores.items():
    print(f"AUROC for {feature}: {score}")

best_feature = max(auroc_scores, key=auroc_scores.get)
best_score = auroc_scores[best_feature]

print(f"The feature with the largest AUROC score is '{best_feature}' with a score of {best_score}.")

"""Q10: Which is a better predictor of whether a song is classical music – duration or the principal
components you extracted in question 8? [Suggestion: You might have to convert the qualitative genre label to a binary numerical label (classical or not)]
"""

data['is_classical'] = data['track_genre'].apply(lambda x: 1 if x == 'classical' else 0)

X_duration = data[['duration']]
y = data['is_classical']

# Split the data into training and testing sets for duration
X_train_dur, X_test_duration, y_train, y_test = train_test_split(X_duration, y, test_size=0.2, random_state=42)

# Train logistic regression model with duration as the predictor
model_duration = LogisticRegression()
model_duration.fit(X_train_dur, y_train)

# Predict probabilities on the test set for duration
y_pred_prob_duration = model_duration.predict_proba(X_test_duration)[:, 1]

# Calculate AUC-ROC score
auc_roc_duration = roc_auc_score(y_test, y_pred_prob_duration)
print("AUC-ROC using duration as predictor:", auc_roc_duration)

X = data[features]
y = data['is_classical']

pca = PCA(n_components=3)
X_pca = pca.fit_transform(zscoredData)

X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

# Train logistic regression model with duration as the predictor
model_pca = LogisticRegression()
model_pca.fit(X_train_pca, y_train)

# Predict probabilities on the test set for duration
y_pred_prob_pca = model_pca.predict_proba(X_test_pca)[:, 1]

# Calculate AUC-ROC score
auc_roc_pca = roc_auc_score(y_test, y_pred_prob_pca)
print("AUC-ROC using principal components as predictor:", auc_roc_pca)

"""Extra credit"""

key_popularity = data.groupby('key')['popularity'].mean()

# Map the numeric key values back to their corresponding musical keys
# For example, 0 represents 'A', 1 represents 'A#', and so on
key_mapping = {
    0: 'A', 1: 'A#', 2: 'B', 3: 'C', 4: 'C#', 5: 'D',
    6: 'D#', 7: 'E', 8: 'F', 9: 'F#', 10: 'G', 11: 'G#'
}
key_popularity.index = key_popularity.index.map(key_mapping)

# Plot the average popularity for each key
plt.figure(figsize=(10, 6))
key_popularity.plot(kind='bar', color='skyblue')
plt.title('Average Popularity by Key')
plt.xlabel('Key')
plt.ylabel('Average Popularity')
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Calculate the standard deviation of popularity for each key group using groupby method
key_std_dev = data.groupby('key')['popularity'].std()

# Map the numeric key values back to their corresponding musical keys
key_std_dev.index = key_std_dev.index.map(key_mapping)

# Print the standard deviation for each key
print("Standard Deviation of Popularity for Each Key:")
print(key_std_dev)

